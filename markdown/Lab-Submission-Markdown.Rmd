---
title: "Business Intelligence Lab Submission Markdown"
author: "Lumin"
date: "1/10/23"
output:
  github_document:
    toc: yes
    toc_depth: 4
    fig_width: 6
    fig_height: 4
    df_print: default
always_allow_html: true
editor_options:
  chunk_output_type: console
---


# Student Details

+---------------------------------------------------+------------------------------------------------------------------------------------------------------+
| **Student ID Numbers and Names of Group Members** | 
|                                                   |                                                                                                      |
|                                                   | 1.  112827 - A - Mungai Kenneth                                                                      |
|                                                   |                                                                                                      |
|                                                   | 2.  123324 - B - Kelly Noella Sota                                                                     |
|                                                   |                                                                                                      |
|                                                   | 3.  134265 - A - Emmanuel Kiptoo                                                                   |
|                                                   |                                                                                                      |
|                                                   |                                                                               |
|                                                   |                                                                                                      |
|                                                   |                                                                               |
+---------------------------------------------------+------------------------------------------------------------------------------------------------------+
| **GitHub Classroom Group Name**                   |    Lumin                                                                                                  |
+---------------------------------------------------+------------------------------------------------------------------------------------------------------+
| **Course Code**                                   | BBT4206                                                                                              |
+---------------------------------------------------+------------------------------------------------------------------------------------------------------+
| **Course Name**                                   | Business Intelligence II                                                                             |
+---------------------------------------------------+------------------------------------------------------------------------------------------------------+
| **Program**                                       | Bachelor of Business Information Technology                                                          |
+---------------------------------------------------+------------------------------------------------------------------------------------------------------+
| **Semester Duration**                             | 21^st^ August 2023 to 28^th^ November 2023                                                           |
+---------------------------------------------------+------------------------------------------------------------------------------------------------------+

# Setup Chunk

**Note:** the following "*KnitR*" options have been set as the defaults:\
`knitr::opts_chunk$set(echo = TRUE, warning = FALSE, eval = TRUE, collapse = FALSE, tidy.opts = list(width.cutoff = 80), tidy = TRUE)`.

More KnitR options are documented here <https://bookdown.org/yihui/rmarkdown-cookbook/chunk-options.html> and here <https://yihui.org/knitr/options/>.

```{r setup, include=FALSE}
library(formatR)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, eval = TRUE,
                      collapse = FALSE, tidy = TRUE)
```

**Note:** the following "*R Markdown*" options have been set as the defaults:

> output:\
> \
> github_document:\
> toc: yes\
> toc_depth: 4\
> fig_width: 6\
> fig_height: 4\
> df_print: default\
> \
> editor_options:\
> chunk_output_type: console


# 1: Install and Load Required Packages:
In this step, we ensure that the necessary R packages are installed and loaded. Packages are collections of R functions, data, and compiled code that extend the functionality of R. The install.packages() function is used to install packages, and library() is used to load them.
```{r setup-chunk-one}
if (require("languageserver")) {
  require("languageserver")
} else {
  install.packages("languageserver", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}

# STEP 1. Install and Load the Required Packages ----
## ggplot2 ----
if (require("ggplot2")) {
  require("ggplot2")
} else {
  install.packages("ggplot2", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}

## caret ----
if (require("caret")) {
  require("caret")
} else {
  install.packages("caret", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}

## mlbench ----
if (require("mlbench")) {
  require("mlbench")
} else {
  install.packages("mlbench", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}

## pROC ----
if (require("pROC")) {
  require("pROC")
} else {
  install.packages("pROC", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}

## dplyr ----
if (require("dplyr")) {
  require("dplyr")
} else {
  install.packages("dplyr", dependencies = TRUE,
                   repos = "https://cloud.r-project.org")
}
library(readr)
```

# 2. Accuracy and Cohen's Kappa ----
This code snippet is used to perform classification tasks on the "Sonar" dataset. Firstly, it loads the dataset and sets a random seed for reproducibility. It then calculates the baseline accuracy for the classification task. The dataset is split into training and testing sets using a 75:25 split. A logistic regression model is trained on the training data using 5-fold cross-validation.
```{r step-two-chunk}
## 2.a. Load the dataset ----
data("Sonar")

# Set a random seed for reproducibility
set.seed(123)

# Create a data frame with the target variable and features
df <- as.data.frame(Sonar)


## 2.b. Determine the Baseline Accuracy ----
# Determine the baseline accuracy
sonar_freq <- Sonar$Class
baseline_accuracy <- sum(sonar_freq == "M") / length(sonar_freq)
cat("Baseline Accuracy:", baseline_accuracy, "\n")

# Define the training control with 5-fold cross-validation
train_control <- trainControl(method = "cv", number = 5)

## 2.c. Split the dataset ----
# Split the dataset into a 75:25 train:test data split
n_train <- round(0.75 * nrow(df))
train_data <- df[1:n_train, ]
test_data <- df[(n_train + 1):nrow(df), ]

## 2.d. Train the Model ----
# Train a classification model (e.g., logistic regression) with 5-fold cross-validation
model <- train(Class ~ ., data = train_data, method = "glm", metric = "Accuracy", trControl = train_control)

# Display the model's performance using the metric calculated by caret when training the model
print(model)

library(readr)
```

## 2.1 Confusion Matrix.
This code loads the "Sonar" dataset, creates a data frame, and trains a classification model (e.g., random forest) using 5-fold cross-validation. It then predicts target values, computes a confusion matrix, and presents classification metrics like accuracy and error rates for the "Sonar" dataset.
```{r step-three-chunk}
# Load the Sonar dataset
data("Sonar")

# Set a random seed for reproducibility
set.seed(123)

# Create a data frame with the target variable and features
df <- as.data.frame(Sonar)

# Define the training control (e.g., 5-fold cross-validation)
train_control <- trainControl(method = "cv", number = 5)

# Train a classification model (e.g., random forest, support vector machine, etc.)
model <- train(Class ~ ., data = df, method = "rf", trControl = train_control)

# Predict on the test set (in this example, using the same data for illustration)
predictions <- predict(model, newdata = df)

# Compute a confusion matrix and other classification metrics
confusion_matrix <- confusionMatrix(predictions, df$Class)
print(confusion_matrix)

library(readr)
```

### 2.2. Display a graphical confusion matrix
```{r step-four-chunk}
fourfoldplot(as.table(confusion_matrix), color = c("grey", "lightblue"),
             main = "Confusion Matrix")
```




# 3. RMSE, R Squared, and MAE:
This code focuses on a regression task using the mtcars dataset. It starts by splitting the data into a training and test set (75:25), then trains a linear regression model with 5-fold cross-validation. The code calculates and displays various regression performance metrics, including RMSE, SSR, SST, R-squared, and MAE. 
```{r step-five-chunk}
## 2.a. Load the dataset ----
data("mtcars")

summary("mtcars")

# Set a random seed for reproducibility
set.seed(123)

# Create a data frame with the target variable and features
df <- as.data.frame(mtcars)

# Define the training control with 5-fold cross-validation
train_control <- trainControl(method = "cv", number = 5)

## 2.b. Split the dataset ----
# Split the dataset into a 75:25 train:test data split
n_train <- round(0.75 * nrow(df))
train_data <- df[1:n_train, ]
test_data <- df[(n_train + 1):nrow(df), ]

# Train a linear regression model with 5-fold cross-validation
model <- train(mpg ~ ., data = train_data, method = "lm", trControl = train_control)

# Display the model's performance using the metric calculated by caret when training the model
print(model)

# Predict on the test set
predictions <- predict(model, newdata = test_data)

# Calculate RMSE
rmse <- sqrt(mean((test_data$mpg - predictions)^2))
cat("RMSE =", rmse, "\n")

# Calculate SSR
ssr <- sum((test_data$mpg - predictions)^2)
cat("SSR =", ssr, "\n")

# Calculate SST
sst <- sum((test_data$mpg - mean(test_data$mpg))^2)
cat("SST =", sst, "\n")

# Calculate R-squared
r_squared <- 1 - (ssr / sst)
cat("R-squared =", r_squared, "\n")

# Calculate MAE
absolute_errors <- abs(predictions - test_data$mpg)
mae <- mean(absolute_errors)
cat("MAE =", mae, "\n")
library(readr)
```


# 4. Area Under ROC Curve:
This code deals with a K-nearest neighbors (KNN) classification model applied to the Sonar dataset. It begins by splitting the data into training and testing sets (80:20), then trains the KNN model with 10-fold cross-validation, focusing on ROC as the evaluation metric. The code calculates and displays the model's sensitivity (True Positive Rate), specificity (True Negative Rate), and AUC (Area Under ROC Curve) using the test dataset. It also generates and plots the ROC curve to visualize the model's performance in distinguishing the "M" class.
```{r step-six-chunk}
library(pROC)

# Split the dataset into a training and testing set
set.seed(7)
train_index <- createDataPartition(Sonar$Class, p = 0.8, list = FALSE)
sonar_train <- Sonar[train_index, ]
sonar_test <- Sonar[-train_index, ]

# Train the KNN model
train_control <- trainControl(method = "cv", number = 10, classProbs = TRUE, summaryFunction = twoClassSummary)
knn_model <- train(Class ~ ., data = sonar_train, method = "knn", metric = "ROC", trControl = train_control)

# Display the model's performance using the metric calculated by caret when training the model
print(knn_model)

# Compute the metric yourself using the test dataset
# Sensitivity and Specificity
predictions <- predict(knn_model, sonar_test[, -ncol(sonar_test)])
actual_labels <- sonar_test$Class  # Use the actual class labels from the test dataset

conf_matrix <- confusionMatrix(predictions, actual_labels)
sensitivity <- conf_matrix$byClass["Sensitivity"]
specificity <- conf_matrix$byClass["Specificity"]

cat("Sensitivity (True Positive Rate) =", sensitivity, "\n")
cat("Specificity (True Negative Rate) =", specificity, "\n")

# AUC
predictions_prob <- as.numeric(predict(knn_model, sonar_test[, -ncol(sonar_test)], type = "prob")[, "M"])
roc_curve <- roc(ifelse(actual_labels == "M", 1, 0), predictions_prob)

cat("AUC (Area Under ROC Curve) =", auc(roc_curve), "\n")

# Plot the ROC curve
plot(roc_curve, main = "ROC Curve for Sonar Model (Class 'M')", col = "blue", lwd = 2.5)
library(readr)
```

# 5. Logarithmic Loss (LogLoss):
In this code, the BreastCancer dataset is loaded and processed to handle missing values using the "mice" package for imputations. Five imputed datasets are created and then combined. A classification model, specifically a decision tree (rpart), is trained on the BreastCancer dataset with 5-fold repeated cross-validation. The performance of the model, evaluated using the log loss metric, is displayed.
```{r step-seven-chunk}
# Load the BreastCancer dataset
data(BreastCancer)

## 4.a. Handle Missing Values ----
# Load the BreastCancer dataset
data(BreastCancer)

## 4.a. Handle Missing Values ----
# Load the BreastCancer dataset
# Load the BreastCancer dataset
data(BreastCancer)

# Load the mice package for imputations
library(mice)

# Impute missing values using mice
imputed_data <- mice(BreastCancer, method = "pmm", m = 5)  # You can change "m" as needed

# Combine the imputed datasets
completed_data <- complete(imputed_data)

# 4.a. Train the Model
# We apply the 5-fold repeated cross-validation resampling method with 3 repeats.
train_control <- trainControl(
  method = "repeatedcv",
  number = 5,
  repeats = 3,
  classProbs = TRUE,
  summaryFunction = mnLogLoss
)
set.seed(7)

# Train a classification model on the BreastCancer dataset.
# In this case, we use a decision tree (rpart) as an example model.
BreastCancer_model_rpart <- train(Class ~ ., data = completed_data, method = "rpart",
                                  metric = "logLoss", trControl = train_control)

# 4.b. Display the Model's Performance
# Use the metric calculated by caret when training the model.
print(BreastCancer_model_rpart)
library(readr)
```